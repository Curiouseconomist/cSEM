% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/postestimate_test_MGD.R
\name{testMGD}
\alias{testMGD}
\title{Tests for multi-group comparison.}
\usage{
testMGD(
 .object                = args_default()$.object,
 .alpha                 = args_default()$.alpha,
 .approach_p_adjust     = args_default()$.approach_p_adjust,
 .approach_mgd          = args_default()$.approach_mgd,
 .model                 = args_default()$.model,
 .handle_inadmissibles  = args_default()$.handle_inadmissibles,
 .R_permutation         = args_default()$.R_permutation,
 .R_bootstrap           = args_default()$.R_bootstrap,
 .saturated             = args_default()$.saturated,
 .seed                  = args_default()$.seed,
 .type_vcv              = args_default()$.type_vcv,
 .verbose               = args_default()$.verbose
 )
}
\arguments{
\item{.object}{An R object of class \link{cSEMResults} resulting from a call to \code{\link[=csem]{csem()}}.}

\item{.alpha}{An integer or a numeric vector of significance levels.
Defaults to \code{0.05}.}

\item{.approach_p_adjust}{Character string. Approach used to adjust the p value.
The methods employed in the \code{\link[stats:p.adjust]{stats::p.adjust()}} can be used.
Defaults to "\emph{none}".}

\item{.approach_mgd}{Character string or a vector of character strings.
Approach used for the multi-group comparison. One: "\emph{all}", "\emph{Klesel}", "\emph{Chin}",
"\emph{Sarstedt}", or "\emph{Keil}. Default to "\emph{all}" in which case all approaches are
computed (if possible).}

\item{.model}{A model in \link[lavaan:model.syntax]{lavaan model syntax} indicating which
parameters (i.e, path (\code{~}), loadings (\code{=~}), or weights (\code{<~})) should be
compared across groups. Defaults to \code{NULL} in which case all parameters of the model
are compared.}

\item{.handle_inadmissibles}{Character string. How should inadmissible results
be treated? One of "\emph{drop}", "\emph{ignore}", or "\emph{replace}". If "\emph{drop}", all
replications/resamples yielding an inadmissible result will be dropped
(i.e. the number of results returned will be less than .R). For "\emph{ignore}"
all results are returned even if they are inadmissible (i.e.
number of results returned = .R). For "\emph{replace}" resampling continues until
there are exactly .R admissible solutions.
Defaults to "\emph{drop}".}

\item{.R_permutation}{Integer. The number of permutations. Defaults to \code{499}}

\item{.R_bootstrap}{Integer. The number of bootstrap runs. Defaults to \code{499}}

\item{.saturated}{Logical. Should a saturated structural model be used?
Defaults to \code{FALSE}.}

\item{.seed}{Integer or NULL. The random seed to use. Defaults to \code{NULL} in which
case an arbitrary seed is choosen.}

\item{.type_vcv}{Character string. Indicates which model-implied correlation matrix is calcuted
One of "\emph{indicator}" or "\emph{construct}". Defaults to "\emph{indicator}".}

\item{.verbose}{Logical. Should information be printed to the console? Defaults
to \code{TRUE}.}
}
\value{
A list of class \code{cSEMTestMGD}. Technically, \code{cSEMTestMGD} is a
named list containing the following list elements:

\describe{
\item{\code{$Information}}{Additional information.}
\item{\code{$Klesel}}{A list with elements, \code{Test_statistic}, \code{P_value}, and \code{Decision}}
\item{\code{$Chin}}{A list with elements, \code{Test_statistic}, \code{P_value}, \code{Decision}, and \code{Decision_overall}}
\item{\code{$Sarstedt}}{A list with elements, \code{Test_statistic}, \code{P_value}, \code{Decision}, and \code{Decision_overall}}
\item{\code{$Keil}}{}
}
}
\description{
This function performs several permutation tests, i.e., the reference distribution
of the test statistic is obtained by permutation.
}
\details{
The following tests are implemented:
\describe{
\item{Approach suggested by \insertCite{Klesel2019;textual}{cSEM}}{
The model-implied variance-covariance matrix (either indicator
\code{.type_vcv = "indicator"} or construct \code{.type_vcv = "construct"})
is compared across groups.

To measure the distance between the model-implied variance-covariance matrices,
the geodesic distance (dG) and the squared Euclidean distance (dL) are used.
If more than two groups are compared, the average distance over all groups
is used.}
\item{Approach suggested by \insertCite{Sarstedt2011;textual}{cSEM}}{
Groups are compared in terms of parameter differences across groups.
\insertCite{Sarstedt2011;textual}{cSEM} tests if parameter k is equal
across all groups. If several parameters are tested simulaneously
it is recommended to adjust the signficance level or the p-values (in \pkg{cSEM} correction is
done by p-value). By default
no multiple testing correction is done, however, several common
adjustments are available via \code{.approach_p_adjust}. See
\code{\link[stats:p.adjust]{stats::p.adjust()}} for details.
}
\item{Approach suggested by \insertCite{Chin2010;textual}{cSEM}}{
Groups are compared in terms of parameter differences across groups.
\insertCite{Chin2010;textual}{cSEM} tests if parameter k is equal
between two groups. If more than two groups are tested the parameter is compared
between all pairs of groups. In this case, it is recommended
to adjust the signficance level or the p-values (in \pkg{cSEM} correction is
done by p-value). If several parameters are tested simultaneously, correction
is by group and number of parameters. By default
no multiple testing correction is done, however, several common
adjustments are available via \code{.approach_p_adjust}. See
\code{\link[stats:p.adjust]{stats::p.adjust()}} for details.
}
\item{Approach suggested by \insertCite{Keil2000;textual}{cSEM}}{
Groups are compared in terms of parameter differences across groups.
\insertCite{Keil2000;textual}{cSEM} tests if parameter k is equal
between two groups. The calculation of the standard error of the parameter
difference is adjusted as proposed by \insertCite{Henseler2009;textual}{cSEM}.
If more than two groups are tested the parameter is compared
between all pairs of groups. In this case, it is recommended
to adjust the signficance level or the p-values (in \pkg{cSEM} correction is
done by p-value). If several parameters are tested simultaneously, correction
is by group and number of parameters. By default
no multiple testing correction is done, however, several common
adjustments are available via \code{.approach_p_adjust}. See
\code{\link[stats:p.adjust]{stats::p.adjust()}} for details.
}
}

Use \code{.approach_mgd} to choose the approach. By default all approaches are computed
(\code{.approach_mgd = "all"})
}
\examples{
\dontrun{
require(cSEM)
data(satisfaction)

model <- "
# Structural model
QUAL ~ EXPE
EXPE ~ IMAG
SAT  ~ IMAG + EXPE + QUAL + VAL
LOY  ~ IMAG + SAT
VAL  ~ EXPE + QUAL

# Measurement model

EXPE <~ expe1 + expe2 + expe3 + expe4 + expe5
IMAG <~ imag1 + imag2 + imag3 + imag4 + imag5
LOY  =~ loy1  + loy2  + loy3  + loy4
QUAL =~ qual1 + qual2 + qual3 + qual4 + qual5
SAT  <~ sat1  + sat2  + sat3  + sat4
VAL  <~ val1  + val2  + val3  + val4
"

listData <- list(satisfaction[-3,], satisfaction[-5, ], satisfaction[-10, ])
out.cSEM <- csem(listData, model) 

testMGD(.object = out.cSEM, .R = 20, .type_vcv= 'construct')
}

}
\references{
\insertAllCited{}
}
\seealso{
\link{cSEMResults}
}
