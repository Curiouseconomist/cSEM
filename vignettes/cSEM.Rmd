---
title: "Introduction to cSEM"
date: "Last edited: `r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
    toc: true
    includes:
      before_body: preamble.mathjax.tex
vignette: >
  %\VignetteIndexEntry{csem-basic}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: ../inst/REFERENCES.bib
---

WARNING: this document is work in progress and may still contain mistakes!
<!-- used to print boldface greek symbols (\mathbf only works for latin symbols) -->
```{r child="preamble-tex.tex", echo=FALSE, include=FALSE}
```
# Preface

Structural equation modeling (SEM) has been used developed for decades
across various research fields such as (among others) psychology, 
sociology, and business research. 

As an almost inevidable consequence, a different terminology system and a distinct 
mathematical notation has evolved within each field over the years. This 
"terminology mess" is one of the major obstacles in interdisciplinary
research and (scientific) debates, since it hampers a broader understanding of 
methodolocial issues, and, even worse,
it promotes systematic missue (e.g., the use of Cronbach's alpha as an estimator for
congeneric reliability). This is particulary
true for those new to SEM or casual applied users who are often overwhelmed
by terminology of their own field only to find that the term they
just thought to have finally grasped is definied differently in another field, 
making the confusion complete.

Ultimately, this is a matter of (mis)communication which, in our opinion, can 
only be satisfactorily solved by establishing a clear, unambigious definition 
for each term and symbol that is used within the package. We emphasize that
we do not seek to impose "our" conventions, nor do we claim they are the
"correct" conventions, but merely seek to make communication
between us (the authors of the package) and you (the package user) as
unambigious and error-free as possible. 

Hence, users are strongly encourgaed to regularily consult the two help files
listed below to avoid potential misunderstandings:

1. The [Terminology][Terminology] help file contains each term that we
   think should be defined and explained in order to make sure
   package users understand complementary help files and vignettes the way
   the package authors intended them to be understood.
1. The [Notation][Notation] help files contains the mathematical notation/
   symbols used in the package documentation alongside a definition.

The package is designed based on a set of principles that are partly in contrast
to commonly used open-source and commerical software packages offering similar content.
This introduction explains these principles, contrasts them against the principles
of existing software packages and points readers to further reading.
Lastly, to use **cSEM** effectively, it is helpful to understand its design. 
Hence, the package architecure and design
as well as what we consider the "cSEM workflow" are discussed in the following.

# Composite-based structural equation modeling
## What is structural equation modeling (SEM)
[Structural equation modeling (SEM)][Terminology] is about modeling the (causal) relationship
between [concepts][Terminology] (an entity defined by a conceptual definition,
e.g. "emotional stability", "self-confidence", "customer loyalty") with other
[concepts][Terminology] and/or observable quantities generally referred to as
[indicators, manifest variables or items][Terminology]. Broadly speaking, two modeling
approaches for the theoretical [concepts][Terminology]  and their relationship exist. We refer to the first as 
[the latent variable model](#lvmodel) and to
the second as [the composite model](#cmodel).
Each approach entails a set of methods, test,
and evaluation criteria as well as a specific terminology that may or may not
be adequate within the realm of the other approach.

### The classical latent variable or common factor model {#lvmodel}
Assuming there are $J$ [concepts][Terminology] and $K$ indicators,
the fundamental feature
of the latent variable model is the assumption of the existence of a set of $J$
[latent variables (common factors)][Terminology] that each serve as a representation of
one of the $J$ [concepts][Terminology] to be studied in a sense that each
[latent variable][Terminology] is at least
partly (causally) responsible for the manifestations of a set of [indicators][Terminology] which
are supposed to measure the [concept][Terminology] in question.
The entirety of these measurement relations is captured by the **measurement model**
which relates [indicators][Terminology] to [latent variables][Terminology]
according to the researchers theory of how observables are related to the
[concepts][Terminology] in question. The entirety of the relationships between
[concepts][Terminology] (i.e., its representation in a statistical model, the [construct][Terminology]) is
captured by the **structural model** whose parameters are usually at the center
of the researchers interest. Caution is warranted though as the [common factor][Terminology]
and its respective [concept][Terminology] are not the same thing. Within the [covariance-based][Terminology]
literature [concept][Terminology], [construct][Terminology], [latent variable][Terminology]
and its representation the
[common factor][Terminology] have often been used interchangeably
[@Rigdon2012; @Rigdon2016; @Rigdon2019].
This will not be the case in **cSEM** and readers are explicitly made aware of the
fact that [concepts][Terminology] are the abstract entity which *may* be modeled by
a [common factor][Terminology], however, no assertion as to the correctness of this approach
in terms of "closeness of the [common factor][Terminology] and its related [concept][Terminology]" are made.

Parameters in latent variable models are usually retrieved by
(full-information) maximum likelihood. The idea is to find parameters
such that the difference between the model-implied
and the empirical indicator covariance matrix is minimized. Such estimation methods
are therefore usually refered to as [covariance-based methods][Terminology]

### The composite model {#cmodel}
The second approach is known as the composite model. As opposed to the latent
variable or common factor model, composites do not presuppose the existence of
a [latent variable][Terminology]. Hence, designed entities (artifacts) such as the
"OECD Better Life Index" that arguably have no latent counterpart may be
adequatly described by a [composite][Terminology], i.e the linear combination of observables defining
the composite. Composites may also be formed to represent [latent variables/common factors][Terminology] 
(or more precisely [concepts][Terminology] modeled as a [common factors][Terminology]) in which case
the [composite][Terminology] serves as a [proxy or stand-in][Terminology] for the the [latent variable][Terminology].
However, in **cSEM**, the term "composite *__model__*" is only used to refer to a model
in a the former sense, i.e., a model in which the [composite][Terminology] is a direct representation
of [concept/construct][Terminology]!


## What is composite-based SEM?

Composite-based SEM is the entirety of methods, approaches, procedures, algorithms
that in some way or another involve linear compounts ([composites][Terminology]), 
i.e., linear combinations of
observables when retriving (estimating) quantities of interest such as the
coefficents of the structural model. It is important to clearly distiguish between 
the *composite model* and what we call *composite-based SEM*. They are not the same.
While the former is "only" *__a__* *model* relating [concepts][Terminology] to observables, 
the latter simply states that [composites][Terminology] - linear compounts, i.e., weighted linear combinations
of observables - are used to retrive quantities of interest, given
a specific modeling approach! Hence, composite-based SEM thus covers common
factor as well as composite models!

As sketched above, common factor and composite models fundamentally differ in how the relation
between observables and [concepts][Terminology] is modeled. Naturally, results and, most notably,
their (correct/meaningful) interpretation critically hinge on what type of model the user
specifies. Across the package we therefore strictly distigusih between

- Concepts modeled as common factors (or alternatively latent variables)
- Concepts modeled as composites

These phrases will repeateatly appear in help files and other complementary files. It
is therefore crucial to remember what they supposed to convey.

# Using cSEM
## The cSEM-Workflow

Usually, working with **cSEM** consists of 4 steps:

1. Preparing/loadings the data to analyse
1. Specifying the model to estimate
1. Using the `csem()` function
1. Applying the postestimation functions to the result of 3.

### Preparing the data

Technically, preparing the data does not require the **cSEM** and is therefore
better considered a preparation task, i.e., a "pre-cSEM" task. The reason why
this step is nevertheless considered an explicit part of the cSEM-workflow is motivated by the experience that
applied/causal users tend to shy away from software like R because
"just getting the data in" and understanding how to show, manipulate and work with
data can be frustrating if one is not aware of R's rich, and easy to learn
data import and data processing capabilities. While these topics may have been
overwhelming for newcommers several years ago, data import and data transformation
have become extremly simple and user-friendly if the right tools packages/ packages
ares used. The best place to start is
the [Rstudio Cheat sheet webpage](https://www.rstudio.com/resources/cheatsheets/),
especially the *Data Import* and the *Data Transformation* cheat sheets.

cSEM is relatively flexible as to the type of data accepted. Currently the following
data types/structures are accepted:

1. A `data.frame` or `tibble` with column names matching the indicator names used
   in the lavaan model description of the measurement or composite model. Possible column
   types or classes of the data provided are: `"logical"` (`TRUE`/`FALSE`),
   `"numeric"` (`"double"` or `"integer"`), `"factor"` (`"ordered"` and/or `"unordered"`)
   or a mix of several types. Additionally, the data may also include **one**
   character column whose column name must be given to `.id`.
   Values of this column are interpreted as group identifiers and `csem()`
   will split the data by levels of that column and run the estimation for each
   level separately.

   **Example:**

   Assuming the following simple model is to be estimated:
    ```{r}
    model <- "
    # Structural model
    EXPE ~ IMAG

    # Reflective measurement model
    EXPE =~ expe1 + expe2
    IMAG =~ imag1 + imag2
    "
    ```
   To estimate the model a data frame with $N$ rows (the observations) and
   $K = 4$ columns with column names `expe1`, `imag1`, `expe2`, `imag2` is required.
   The order of the columns in the dataset is irrelevant. In **cSEM** the order
   is defined by the order in which the names appear in the measurment or
   composite model equations in the
   model description. In this case any resulting matrix or vector whose (row/column)
   names contain the indicator names would have the order `expe1`, `expe2`,
   `imag1`, `imag2`.

1. A `matrix` with column names matching the indicator names used
   in the lavaan model description of the measurement model.

1. A list of data frames or matrices. In this case estimation is repeated for
   each data frame or matrix seperately.

### Specfiying a model {#specifyingamodel}
Models are defined using [lavaan model syntax](http://lavaan.ugent.be/tutorial/syntax1.html).
Currently, only the "standard" lavaan model syntax is supported. This comprises:

1. The definition of a latent variable/common factor (or more precicly: the definition of a concept
   modeled as a common factor) by the "`=~`" operator.
2. The defintion of a composite (or more precicly: the definition of a concept
   modeled as a composite) by the "`<-`" operator.
3. The specification of regression equations by the "`~`" operator.
4. The definition of error (co)variances using the "`~~`" operator.

**cSEM** handles linear, nonlinear and hierachical models. Syntax for each
model is illustrated below using variables of the build-in `satisfaction` dataset.
For more information please see the [lavaan syntax tutorial](http://lavaan.ugent.be/tutorial/syntax1.html).

#### Linear model
A typical linear model would looks like this:
```{r eval=FALSE}
model <- "
# Structural model
EXPE ~ IMAG
QUAL ~ EXPE
VAL  ~ EXPE + QUAL
SAT  ~ IMAG + EXPE + QUAL + VAL
LOY  ~ IMAG + SAT

# Composite model
IMAG <~ imag1 + imag2 + imag3                  # composite
EXPE <~ expe1 + expe2 + expe3                  # composite
QUAL <~ qual1 + qual2 + qual3 + qual4 + qual5  # composite
VAL  <~ val1  + val2  + val3                   # composite

# Reflective measurement model
SAT  =~ sat1  + sat2  + sat3  + sat4           # common factor
LOY  =~ loy1  + loy2  + loy3  + loy4           # common factor
"
```
Note that the opeartor `<~` tells **cSEM** that the concept to its left is modelled as a composite;
the operator `=~` tells **cSEM** that the concept to its left is modelled
as a common factor.

#### Nonlinear model

Nonlinear terms are specified as interactions using the dot operator `"."`.
Nonlinear terms include interactions and exponential terms. The latter is
described in model syntax as an "interaction with itself", e.g.,
`x_1^3 = x1.x1.x1`. Currently the following terms are allowed

- Single, e.g., `eta1`
- Quadratic, e.g., `eta1.eta1`
- Cubic, e.g., `eta1.eta1.eta1`
- Two-way interaction, e.g., `eta1.eta2`
- Three-way interaction, e.g., `eta1.eta2.eta3`
- Quadratic and two-way interaction, e.g., `eta1.eta1.eta3`

A simple example would look like this:
```{r}
model <- "
# Structural model
EXPE ~ IMAG + IMAG.IMAG

# Composite model
EXPE <~ expe1 + expe2
IMAG <~ imag1 + imag2
"
```

#### Hiearchical (second order) model

Currently only second-order models are supported. Specification of the
second-order construct takes place in the measurement/composite model.
```{r, eval=FALSE}
model <- "
# Structural model
SAT ~ QUAL
VAL ~ SAT + QUAL

# Reflective measurement model
SAT  =~ sat1 + sat2
VAL  =~ val1 + val2

# Composite model
IMAG <~ imag1 + imag2
EXPE <~ expe1 + expe2

# Second-order term
QUAL =~ IMAG + EXPE
"
```
In this case `QUAL` is modeled as a second-order common factor measuring  `IMAG` and `EXPE`,
where `IMAG` is modeled as a composite and and `EXPE` is itself a common factor.

### Using `csem()`

`csem()` is the central function of the package. Although it is possible to
estimate a model using individual functions called by `csem()` (such as
`parseModel()`, `processData()`, `calculateWeightsPLS()` etc.) using R's `:::`
mechanism for non-exported functions, it is virturally
always easier, saver and quicker to use `csem()` instead.

`csem()` accepts all models and data types described above. The result of a call to
`csem()`is always an object of class `cSEMResults`. Technically, the resulting
object has an additional class attribute, namely `cSEMResults_default`, `cSEMResults_multi`
or `cSEMResults_2ndorder` that depends on the type of model and/or data provided,
however, users usually dont need to worry since postestimation
functions automatically work on all classes.

The simplest possible call to `csem()` involes a dataset and a model:
```{r warning=FALSE, message=FALSE}
require(cSEM)

model <- "
# Path model / Regressions
eta2 ~ eta1
eta3 ~ eta1 + eta2

# Reflective measurement model
eta1 =~ y11 + y12 + y13
eta2 =~ y21 + y22 + y23
eta3 =~ y31 + y32 + y33
"

a <- csem(.data = threecommonfactors, .model = model)
a
```
This is equal to:
```{r, eval=FALSE}
csem(
   .data                        = threecommonfactors,
   .model                       = model,
   .approach_cor_robust         = "none",
   .approach_nl                 = "sequential",
   .approach_paths              = "OLS",
   .approach_weights            = "PLS-PM",
   .conv_criterion              = "diff_absolute",
   .disattenuate                = TRUE,
   .dominant_indicators         = NULL,
   .estimate_structural         = TRUE,
   .id                          = NULL,
   .iter_max                    = 100,
   .normality                   = FALSE,
   .PLS_approach_cf             = "dist_squared_euclid",
   .PLS_ignore_structural_model = FALSE,
   .PLS_modes                   = NULL,
   .PLS_weight_scheme_inner     = "path",
   .reliabilities               = NULL,
   .starting_values             = NULL,
   .tolerance                   = 1e-05,
   .resample_method             = "none",
   .resample_method2            = "none",
   .R                           = 499,
   .R2                          = 199,
   .handle_inadmissibles        = "drop",
   .user_funs                   = NULL,
   .eval_plan                   = "sequential",
   .seed                        = NULL,
   .sign_change_option          = "no"
    )
```
See the `csem()` documentation for details.

#### Inference

By default no inferential quantities are calculated since most composite-based approaches
do not have closed-form solutions for standard errors. **cSEM** relies on the
 `bootstrap` or `jackknife`  to estimate standard errors, test statistics,
and critical quantiles.

**cSEM** offers two ways to compute resamples:

1. Inference can be done by first setting `.resample_method` to
`"jackkinfe"` or `"bootstrap"` and subsequently using `summarize()` or `infer()`.
2. The same result is achieved by passing a `cSEMResults` object to `resamplecSEMResults()`
and subsequently using `summarize()` or `infer()`.

```{r eval=FALSE}
# Setting `.resample_method`
b1 <- csem(.data = satisfaction, .model = model, .resample_method = "bootstrap")
b2 <- resamplecSEMResults(a)
```

Several confidence intervals are implemented, see `?infer()`:

```{r eval=FALSE}
summarize(b1)
infer(b1, .quantity = c("CI_standard_z", "CI_percentile")) # no print method yet
```

Both bootstrap and jackknife resampling support platform-independent multiprocessing
as well as random seeds via the [future framework](https://github.com/HenrikBengtsson/future).
For multiprocessing simply set `.eval_plan = "multiprocess"` in which case the maximum number of available cores
is used if not on Windows. On Windows as many separate R instances are opened in the
backround as there are cores available instead. Note
that this naturally has some overhead so for a small number of resamples multiprocessing
will not always be faster compared to sequential (single core) processing (the default).
Seeds are set via the `.seed` argument.

```{r eval=FALSE}
b <- csem(
  .data            = satisfaction,
  .model           = model,
  .resample_method = "bootstrap",
  .R               = 999,
  .seed            = 98234,
  .eval_plan       = "multiprocess")
```

### Applying a postestimation function

Currently, there are 4 major postestimation function and 4 test-family functions:

`assess()`

:   Assess the quality of the estimated model *without conducting a statistical test*.
    Quality in this case is taken to be a catch-all term for all common aspects 
    of model assessment. This mainly comprises fit indices, reliability 
    estimates, common validity assessment criteria and other related quality 
    measures/indices that do not rely on a formal test procedure. In **cSEM** 
    a generic (fit) index or quality/assessment measure is refered to as
    a **quality criterion**.
    
`predict()`

:   Predict the scores of the exogenous constructs. (not yet implemented).

`summarize()`

:   Summarize a model. The function is mainly called for its side effect, the printing of
    a structured summary of the estimates.
   
`verify()`

:   Verify admissibility of the estimated quantities for a given model. 
    Results based on an estimated model exhibiting one of the following defects 
    are deemed inadmissible: non-convergence, loadings and/or (congeneric) reliabilities 
    larger than 1, a construct VCV and/or a model-implied VCV matrix that 
    is not positive (semi-)definite. 

#### The `test_*` family of postestimation functions

`testHausman2()`

:   The regression-based Hausman test.

`testOMF()` 

:   Test for overall model fit based on @Beran1985. See also @Dijkstra2015.
    
`testMGD()`

:   Test for group differences using difference measures

`testMICOM()`

:   Test of measurement invariance of composites proposed by @Henseler2016

Postestimation functions are generic function with methods for objects of class
`cSEMResults_default`, `cSEMResults_multi`, `cSEMResults_2ndorder`. In **cSEM**
every `cSEMResults_*` object must also have class `cSEMResults` for internal reasons.
When using one of the major postestimation functions, method dispatch is therefore
technically done on one of the `cSEMResults_*` class attributes, ignoring the
`cSEMResults` class attribute. As long as a postestimation function is
used directly method dispatch is not of any practical concern to the end-user.
The difference, however, becomes important if a user seeks to directly invoke an internal function
which is called by one of the postestimation functions (e.g., `calculateAVE()` or
`calculateHTMT()` as called by `assess()`).
In this case only objects of class `cSEMResults_default` are accepted as this
ensures a specific structure. Therefore, it is important to remember that
*internal functions are generally **not** generic.*

## Principles underlying cSEM

cSEM is based on a number of principles, that have had an influence on the design 
of the package.

### Model vs. Estimation

The way different concepts and their relationship
are *modeled* is strictly distinct from how they are *estimated*. Hence we
strictly distinguish between concepts modeled as common factors (or composites)
and the actual estimation **for a given model**.

<!-- To provide a model use the [lavaan model syntax][Lavaan]. -->
<!-- Note, however, that cSEM currently only supports the "standard" lavaan -->
<!-- model syntax (Types 1, 2, 3, and 7 as described on the help page). -->
<!-- Therefore, specifying e.g. a threshold or scaling factors is ignored. -->
<!-- Alternatively, a standardized (possibly incomplete) `cSEMModel`-list may be supplied. -->
<!-- See: [Specifying a model](#specifyingamodel) below for details. -->

<!-- **Example** -->
<!-- ```{r, eval = FALSE} -->
<!-- model <- " -->
<!-- ## Structural model -->
<!-- eta2 ~ eta1 -->

<!-- ## Measurement model -->
<!-- eta1 <~ item1 + item2 + item3 # eta1 is modeled as a composite -->
<!-- eta2 =~ item4 + item5 + item6 # eta2 is modeled as a common factor -->
<!-- " -->
<!-- ``` -->



### Composites in a composite model vs. composites in a common factor model and disattenuation
By virtue of the package, **cSEM** uses composite-based estimators only. Depending
on the model choosen, linear compounts may therefore either serve as a
composite as part of the composite model or as a proxy/stand-in for a common factor.
If a concept is modeled as a common factor, proxy correlations, proxy-indicator
correlations and path coeffcients are inconsistent estimates for their supposed
construct level counterparts (construct correlations, loadings and
path coefficients) unless the proxy is a perfect representation of its
construct level counterpart. This is commonly refered to as **attentuation bias**.
Several approaches have been suggested to correct for these biases.
In **cSEM** estimates are correctly dissattenuated by default if any of the
concepts involved are modeled as a common factor! Disattentuation is controlled
by the `.disattenuate` argument of `csem()`

**Example**
```{r eval=FALSE}
model <- "
## Structural model
eta2 ~ eta1

## Measurement model
eta1 <~ item1 + item2 + item3
eta2 =~ item4 + item5 + item6
"

# Identical
csem(threecommonfactors, model)
csem(threecommonfactors, model, .disattenuate = TRUE)

# To supress automatic disattenuation
csem(threecommonfactors, model, .disattenuate = FALSE)
```

Note that since `.approach_weights = "PLS-PM"` and `.disattentuate = TRUE`
by default (see for [The role of the weighting scheme and partial least squares (PLS)](#roleofpls) below)
and one of the concepts in the model above is modeled as a common factor,
composite (proxy) correlations, loadings and path coefficients are adequately
disattenuated using the correction approach commonly known as **consistent partial
least squares (PLSc)**.
If `.disattenuate = FALSE` or all concepts are modeled as composites "proper"
PLS values are returned. To learn more about disattenuation, see the Methods
and Formulae section of the respective weighting approach.

### The role of the weighting scheme and partial least squares (PLS) {#roleofpls}

In principal, any weighted combination of
appropriately choosen observables can be used to estimate structural relationships
between these compounts. Hence, any conceptual or methodological issue
disscussed based on a composite build by a given (weighting) approach may
equally well be discussed for any other potential weighting scheme. The
appropriatness or potential superiority of a specific weighting approach such as
"partial least squares path modeling" (PLS) over another such as "unit weights" (sum scores) 
is therfore to some extent a question of *relative* appropriatness and
*relative* superiority.

As a notable consequence, we belief that well known approach such partial least
squares path modeling (PLS) and generalized structured component analysis (GSCA)
are - contrary to common belief - best exclusivly understood as prescriptions for forming
linear compunts based on observables, i.e. as weighting approaches. Not more, not less.
In cSEM this is reflected by the fact that `"PLS"` and `"GSCA"` are choices of 
the `.approach_weights` argument.

```{r eval=FALSE}
model <- "
## Structural model
eta2 ~ eta1

## Composite model
eta1 <~ item1 + item2 + item3
eta2 <~ item4 + item5 + item6
"

### Currently the following weight approaches are implemented
# Partial least squares path modeling (PLS)
csem(threecommonfactors, model, .approach_weights = "PLS-PM") # default

# Generalized canonical correlation analysis (Kettenring approaches)
csem(threecommonfactors, model, .approach_weights = "SUMCORR")
csem(threecommonfactors, model, .approach_weights = "MAXVAR")
csem(threecommonfactors, model, .approach_weights = "SSQCORR")
csem(threecommonfactors, model, .approach_weights = "MINVAR")
csem(threecommonfactors, model, .approach_weights = "GENVAR")

# Generalized structured component analysis (GSCA)
csem(threecommonfactors, model, .approach_weights = "GSCA")

# Principal component analysis (PCA)
csem(threecommonfactors, model, .approach_weights = "PCA")

# Factor score regression (FSR) using "unit", "bartlett" or "regression" weights
csem(threecommonfactors, model, .approach_weights = "unit")
csem(threecommonfactors, model, .approach_weights = "bartlett")
csem(threecommonfactors, model, .approach_weights = "regression")
```

# Literature


[Assess]: https://m-e-rademaker.github.io/cSEM/articles/Using-assess.html
[Lavaan]: http://lavaan.ugent.be/tutorial/index.html
[Notation]: https://m-e-rademaker.github.io/cSEM/articles/Notation.html
[Testing]: https://m-e-rademaker.github.io/cSEM/articles/Using-test.html
[Terminology]: https://m-e-rademaker.github.io/cSEM/articles/Terminology.html
